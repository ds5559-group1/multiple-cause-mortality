{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DS5559 Final Project\n",
    "\n",
    "#### Predicting Primary Cause of Death from Demographic Features\n",
    "\n",
    "No downsampling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".master(\"local[*]\") \\\n",
    ".appName(\"spark_setup\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200579"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in train data\n",
    "train_data = spark.read.option(\"header\",True).option(\"inferSchema\",True).csv(\"train_data\")\n",
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset with potential features\n",
    "training = train_data.select(\"ucd\", \"education\", \"sex\", \"age\", \"marital_status\", \"hispanic_race_recode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip UCD codes to include first letter only\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "training = training.withColumn(\"ucd_short\", regexp_replace('ucd', '\\\\d+', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace age coding values: \n",
    "def replace(column, value):\n",
    "    return when(column != value, column)\n",
    "\n",
    "training = training.withColumn(\"age\", replace(col(\"age\"), 999)) # change age value coded as unknown (999) to null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.filter(training.age == 999).count() # yes - 999 codes have been replaced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|ucd_short| count|\n",
      "+---------+------+\n",
      "|        I|674836|\n",
      "|        C|477413|\n",
      "|        J|216611|\n",
      "|        G|159912|\n",
      "|        F|111510|\n",
      "+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.groupby(\"ucd_short\").count().orderBy('count', ascending=False).show(5) # top 5 causes of death with counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---+---+--------------+--------------------+---------+\n",
      "|ucd|education|sex|age|marital_status|hispanic_race_recode|ucd_short|\n",
      "+---+---------+---+---+--------------+--------------------+---------+\n",
      "|  0|    54142|  0|382|         16592|                7871|        0|\n",
      "+---+---------+---+---+--------------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.select([count(when(col(c).isNull(), c)).alias(c) for c in training.columns]).show() # rows with null values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200579"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.count() # rows in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null or nans\n",
    "training = training.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2136639"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9055989355528666"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 - (2136639/2200579))*100 # dropped 2.9% of dataset because of null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StringIndexer transformers to encode categorical features as numerical for vector assembly.\n",
    "# Can't make this work with multiple columns but docs say it's possible.  spark 3.0 difference?\n",
    "\n",
    "indexer1 = StringIndexer(inputCol=\"marital_status\", outputCol=\"marital_status_index\")\n",
    "indexer2 = StringIndexer(inputCol=\"sex\", outputCol=\"sex_index\")\n",
    "indexer3 = StringIndexer(inputCol='ucd_short', outputCol='ucd_short_c')\n",
    "\n",
    "indexed1 = indexer1.fit(training).transform(training)\n",
    "indexed2 = indexer2.fit(indexed1).transform(indexed1)\n",
    "indexed = indexer3.fit(indexed2).transform(indexed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|ucd_short_c|ucd_short|\n",
      "+-----------+---------+\n",
      "|        0.0|        I|\n",
      "|        6.0|        E|\n",
      "|        1.0|        C|\n",
      "|       21.0|        H|\n",
      "|        3.0|        G|\n",
      "|       20.0|        O|\n",
      "|        5.0|        X|\n",
      "|        9.0|        A|\n",
      "|       14.0|        B|\n",
      "|        2.0|        J|\n",
      "|       13.0|        D|\n",
      "|        4.0|        F|\n",
      "|       19.0|        L|\n",
      "|       11.0|        V|\n",
      "|       10.0|        W|\n",
      "|       18.0|        Q|\n",
      "|       22.0|        U|\n",
      "|       12.0|        R|\n",
      "|        7.0|        K|\n",
      "|       15.0|        Y|\n",
      "|        8.0|        N|\n",
      "|       17.0|        P|\n",
      "|       16.0|        M|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save UCD mappings \n",
    "ucd_xref = indexed.select('ucd_short_c', 'ucd_short').distinct()\n",
    "ucd_xref.show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder transformer to prepare categorical features for model\n",
    "encoder = OneHotEncoderEstimator(inputCols =[\"hispanic_race_recode\", \"education\", \"marital_status_index\"],\n",
    "                                 outputCols = [\"cat_hispanic_race_recode\", \"cat_education\", \"cat_marital_status\"])\n",
    "\n",
    "\n",
    "model = encoder.fit(indexed)\n",
    "encoded = model.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorAssembler to package the features for model\n",
    "assembler = VectorAssembler(inputCols=[\"cat_hispanic_race_recode\", \"cat_education\", \"cat_marital_status\", \"sex_index\", \"age\"],\n",
    "                            outputCol=\"features\")\n",
    "output = assembler.transform(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup = output.select(\"ucd_short_c\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, holdout_set = cleanup.randomSplit(weights=[0.8, 0.2], seed=212) ## split into train set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|ucd_short_c|count|\n",
      "+-----------+-----+\n",
      "|       22.0|    2|\n",
      "|       21.0|   91|\n",
      "|       20.0|  698|\n",
      "|       19.0| 2992|\n",
      "|       18.0| 5881|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set.groupby(\"ucd_short_c\").count().sort('count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are only 2 observations for group '22' and 91 for group '21' - filter out for now \n",
    "\n",
    "train_set = train_set.filter(train_set.ucd_short_c != 22)\n",
    "train_set = train_set.filter(train_set.ucd_short_c != 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|ucd_short_c|count|\n",
      "+-----------+-----+\n",
      "|       20.0|  698|\n",
      "|       19.0| 2992|\n",
      "|       18.0| 5881|\n",
      "|       17.0| 6413|\n",
      "|       16.0| 8471|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set.groupby(\"ucd_short_c\").count().sort('count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.select('ucd_short_c').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now 21 different outcomes for UCD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/2.4.7/ml-classification-regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"ucd_short_c\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = dt.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_output = dt_model.transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"ucd_short_c\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(dt_train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy: 34.7911775872387%\n"
     ]
    }
   ],
   "source": [
    "print('DT Accuracy: ' + str(accuracy*100) + '%')\n",
    "# print('DT Test Error: ' + str((1.0 - accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_52c2d7a5328c) of depth 5 with 39 nodes\n"
     ]
    }
   ],
   "source": [
    "print(dt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "\n",
    "# # save model\n",
    "# dt_model.save('home/ds5559/final_project/models/dt_model')\n",
    "# modeldf = spark.read.parquet('home/ds5559/final_project/models/dt_model/'+\"data/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize decision tree\n",
    "# noderows = modeldf.select(\"id\",\"prediction\",\"leftChild\",\"rightChild\",\"split\").collect()\n",
    "# df = pd.Dataframe([[rw['id'],rw['gain],rw['impurity'],rw['gini']] for rw in noderows if rw['leftChild'] < 0 and rw['rightChild'] < 0])\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predictions = dt_model.transform(holdout_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_predictions.groupby(\"prediction\").count().sort('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred_accuracy = evaluator.evaluate(dt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Validation Hold-out Set Prediction Accuracy: 34.82968765730099%\n"
     ]
    }
   ],
   "source": [
    "print('DT Validation Hold-out Set Prediction Accuracy: ' + str(dt_pred_accuracy*100) + '%')\n",
    "# print('DT Hold-out Set Test Error: ' + str((1.0 - dt_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol='ucd_short_c', featuresCol=\"features\", numTrees=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_output = rf_model.transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"ucd_short_c\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "rf_accuracy = evaluator.evaluate(rf_train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy: 34.287673180185784%\n"
     ]
    }
   ],
   "source": [
    "print('RF Accuracy: ' + str(rf_accuracy*100) + '%')\n",
    "# print('RF Test Error: ' + str((1.0 - rf_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassificationModel (uid=RandomForestClassifier_3f787b98fc9e) with 100 trees\n"
     ]
    }
   ],
   "source": [
    "print(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions = rf_model.transform(holdout_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_predictions.groupby(\"prediction\").count().sort('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_accuracy = evaluator.evaluate(rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Validation Hold-out Set Prediction Accuracy: 34.27950000819428%\n"
     ]
    }
   ],
   "source": [
    "print('RF Validation Hold-out Set Prediction Accuracy: ' + str(rf_pred_accuracy*100) + '%')\n",
    "# print('RF Hold-out Set Test Error: ' + str((1.0 - rf_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(labelCol='ucd_short_c', featuresCol=\"features\", smoothing=1.0, modelType=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = nb.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_output = nb_model.transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"ucd_short_c\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "nb_accuracy = evaluator.evaluate(nb_train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Accuracy: 31.846024877458362%\n"
     ]
    }
   ],
   "source": [
    "print('NB Accuracy: ' + str(nb_accuracy*100) + '%')\n",
    "# print('RF Test Error: ' + str((1.0 - rf_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes_4ba42fab39b4\n"
     ]
    }
   ],
   "source": [
    "print(nb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = nb_model.transform(holdout_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_predictions.groupby(\"prediction\").count().sort('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pred_accuracy = evaluator.evaluate(nb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Validation Hold-out Set Prediction Accuracy: 31.85071419039302%\n"
     ]
    }
   ],
   "source": [
    "print('NB Validation Hold-out Set Prediction Accuracy: ' + str(nb_pred_accuracy*100) + '%')\n",
    "# print('RF Hold-out Set Test Error: ' + str((1.0 - rf_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "mlr = LogisticRegression(labelCol='ucd_short_c', featuresCol=\"features\", family = \"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_model = mlr.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(str(mlr_model.coefficientMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_train_output = mlr_model.transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"ucd_short_c\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "mlr_accuracy = evaluator.evaluate(mlr_train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR Accuracy: 34.532376205014685%\n"
     ]
    }
   ],
   "source": [
    "print('MLR Accuracy: ' + str(mlr_accuracy*100) + '%')\n",
    "# print('MLR Test Error: ' + str((1.0 - mlr_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionModel: uid = LogisticRegression_a07e431f7742, numClasses = 23, numFeatures = 30\n"
     ]
    }
   ],
   "source": [
    "print(mlr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_predictions = mlr_model.transform(holdout_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlr_predictions.groupby(\"prediction\").count().sort('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_pred_accuracy = evaluator.evaluate(mlr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR Validation Hold-out Set Prediction Accuracy: 34.540312366111245%\n"
     ]
    }
   ],
   "source": [
    "print('MLR Validation Hold-out Set Prediction Accuracy: ' + str(mlr_pred_accuracy*100) + '%')\n",
    "# print('MLR Hold-out Set Test Error: ' + str((1.0 - mlr_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Hold-Out Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550650"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in test data\n",
    "test_data = spark.read.option(\"header\",True).option(\"inferSchema\",True).csv(\"test_data\")\n",
    "test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset with potential features\n",
    "testing = test_data.select(\"ucd\", \"education\", \"sex\", \"age\", \"marital_status\", \"hispanic_race_recode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip UCD codes to include first letter only\n",
    "testing = testing.withColumn(\"ucd_short\", regexp_replace('ucd', '\\\\d+', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+---+---+--------------+--------------------+---------+\n",
      "| ucd|education|sex|age|marital_status|hispanic_race_recode|ucd_short|\n",
      "+----+---------+---+---+--------------+--------------------+---------+\n",
      "| C61|        1|  M| 82|             M|                   7|        C|\n",
      "|E142|        1|  F| 74|             M|                   1|        E|\n",
      "|I429|        2|  M| 70|             S|                   8|        I|\n",
      "|C349|        3|  M| 89|             W|                   6|        C|\n",
      "|I119|        3|  M| 67|             S|                   7|        I|\n",
      "+----+---------+---+---+--------------+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace age coding values: \n",
    "testing = testing.withColumn(\"age\", replace(col(\"age\"), 999)) # change age value coded as unknown (999) to null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null or nans\n",
    "testing = testing.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534741"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with ucd_short_c cross reference - want to ensure that string indexing matches between train and test data!\n",
    "testing = testing.join(ucd_xref, on = 'ucd_short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---------+---+---+--------------+--------------------+-----------+\n",
      "|ucd_short| ucd|education|sex|age|marital_status|hispanic_race_recode|ucd_short_c|\n",
      "+---------+----+---------+---+---+--------------+--------------------+-----------+\n",
      "|        K|K922|        3|  F| 94|             W|                   6|        7.0|\n",
      "|        K|K746|        2|  M| 72|             M|                   6|        7.0|\n",
      "|        K|K650|        3|  M| 86|             W|                   6|        7.0|\n",
      "|        K|K922|        3|  F| 81|             W|                   6|        7.0|\n",
      "|        K|K746|        3|  F| 72|             M|                   6|        7.0|\n",
      "+---------+----+---------+---+---+--------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StringIndexer transformers to encode categorical features as numerical for vector assembly.\n",
    "# leaving off the ucd indexer here - already joined with ucd_xref\n",
    "\n",
    "indexed1 = indexer1.fit(testing).transform(testing)\n",
    "indexed = indexer2.fit(indexed1).transform(indexed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---------+---+---+--------------+--------------------+-----------+--------------------+---------+\n",
      "|ucd_short| ucd|education|sex|age|marital_status|hispanic_race_recode|ucd_short_c|marital_status_index|sex_index|\n",
      "+---------+----+---------+---+---+--------------+--------------------+-----------+--------------------+---------+\n",
      "|        K|K922|        3|  F| 94|             W|                   6|        7.0|                 1.0|      1.0|\n",
      "|        K|K746|        2|  M| 72|             M|                   6|        7.0|                 0.0|      0.0|\n",
      "+---------+----+---------+---+---+--------------+--------------------+-----------+--------------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder transformer to prepare categorical features for model\n",
    "model = encoder.fit(indexed)\n",
    "encoded = model.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorAssembler to package the features for model\n",
    "output = assembler.transform(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup = output.select(\"ucd_short_c\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|ucd_short_c|count|\n",
      "+-----------+-----+\n",
      "|       21.0|   21|\n",
      "|       20.0|  209|\n",
      "|       19.0|  951|\n",
      "|       18.0| 1745|\n",
      "|       17.0| 1990|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanup.groupby(\"ucd_short_c\").count().sort('count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out groups '20' and '21' (consistent with training data pre-processing)\n",
    "\n",
    "cleanup = cleanup.filter(cleanup.ucd_short_c != 22)\n",
    "cleanup = cleanup.filter(cleanup.ucd_short_c != 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling - Holdout Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predictions_f = dt_model.transform(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred_accuracy_f = evaluator.evaluate(dt_predictions_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Final Hold-out Set Prediction Accuracy: 34.783438061041295%\n"
     ]
    }
   ],
   "source": [
    "print('DT Final Hold-out Set Prediction Accuracy: ' + str(dt_pred_accuracy_f*100) + '%')\n",
    "# print('DT Hold-out Set Test Error: ' + str((1.0 - dt_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions_f = rf_model.transform(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_accuracy_f = evaluator.evaluate(rf_predictions_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Final Hold-out Set Prediction Accuracy: 34.31291143028127%\n"
     ]
    }
   ],
   "source": [
    "print('RF Final Hold-out Set Prediction Accuracy: ' + str(rf_pred_accuracy_f*100) + '%')\n",
    "# print('DT Hold-out Set Test Error: ' + str((1.0 - dt_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions_f = nb_model.transform(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pred_accuracy_f = evaluator.evaluate(nb_predictions_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Validation Hold-out Set Prediction Accuracy: 31.813098444045483%\n"
     ]
    }
   ],
   "source": [
    "print('NB Validation Hold-out Set Prediction Accuracy: ' + str(nb_pred_accuracy_f*100) + '%')\n",
    "# print('MLR Hold-out Set Test Error: ' + str((1.0 - mlr_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_predictions_f = mlr_model.transform(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_pred_accuracy_f = evaluator.evaluate(mlr_predictions_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR Validation Hold-out Set Prediction Accuracy: 34.5384500299222%\n"
     ]
    }
   ],
   "source": [
    "print('MLR Validation Hold-out Set Prediction Accuracy: ' + str(mlr_pred_accuracy_f*100) + '%')\n",
    "# print('MLR Hold-out Set Test Error: ' + str((1.0 - mlr_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_summary = mlr_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = mlr_summary.accuracy\n",
    "falsePositiveRate = mlr_summary.weightedFalsePositiveRate\n",
    "truePositiveRate = mlr_summary.weightedTruePositiveRate\n",
    "fMeasure = mlr_summary.weightedFMeasure()\n",
    "precision = mlr_summary.weightedPrecision\n",
    "recall = mlr_summary.weightedRecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34532376205014687\n",
      "FPR: 0.251448908622885\n",
      "TPR: 0.3453237620501469\n",
      "F-measure: 0.2436907510505344\n",
      "Precision: 0.22353801080339267\n",
      "Recall: 0.3453237620501469\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/thd6tp/ds5559/final_project/Classification_Models.ipynb to pdf\n",
      "[NbConvertApp] Writing 85997 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 75070 bytes to /sfs/qumulo/qhome/thd6tp/ds5559/final_project/Classification_Models.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/thd6tp/ds5559/final_project/Classification_Models_DS.ipynb to pdf\n",
      "[NbConvertApp] Writing 98157 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 83886 bytes to /sfs/qumulo/qhome/thd6tp/ds5559/final_project/Classification_Models_DS.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/thd6tp/ds5559/final_project/LogRegModel_Demog.ipynb to pdf\n",
      "[NbConvertApp] Writing 130503 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 114194 bytes to /sfs/qumulo/qhome/thd6tp/ds5559/final_project/LogRegModel_Demog.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/thd6tp/ds5559/final_project/Pipelines.ipynb to pdf\n",
      "[NbConvertApp] Writing 21300 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 13835 bytes to /sfs/qumulo/qhome/thd6tp/ds5559/final_project/Pipelines.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/thd6tp/ds5559/final_project/TreeModels_DownSample_TDP.ipynb to pdf\n",
      "[NbConvertApp] Writing 108228 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 94160 bytes to /sfs/qumulo/qhome/thd6tp/ds5559/final_project/TreeModels_DownSample_TDP.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/thd6tp/ds5559/final_project/TreeModels_TDP.ipynb to pdf\n",
      "[NbConvertApp] Writing 57450 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 59830 bytes to /sfs/qumulo/qhome/thd6tp/ds5559/final_project/TreeModels_TDP.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/thd6tp/ds5559/final_project/secondary_cause_PC.ipynb to pdf\n",
      "[NbConvertApp] Writing 60958 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 56250 bytes to /sfs/qumulo/qhome/thd6tp/ds5559/final_project/secondary_cause_PC.pdf\n"
     ]
    }
   ],
   "source": [
    "# Save notebook as PDF document\n",
    "!jupyter nbconvert --to pdf `pwd`/*.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
