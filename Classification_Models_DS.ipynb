{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DS5559 Final Project\n",
    "\n",
    "#### Predicting Primary Cause of Death from Demographic Features\n",
    "\n",
    "Downsampled data to balance primary cause of death class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".master(\"local[*]\") \\\n",
    ".appName(\"spark_setup\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200579"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in train data\n",
    "train_data = spark.read.option(\"header\",True).option(\"inferSchema\",True).csv(\"train_data\")\n",
    "train_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset with potential features\n",
    "training = train_data.select(\"ucd\", \"education\", \"sex\", \"age\", \"marital_status\", \"hispanic_race_recode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip UCD codes to include first letter only\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "training = training.withColumn(\"ucd_short\", regexp_replace('ucd', '\\\\d+', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace age coding values: \n",
    "def replace(column, value):\n",
    "    return when(column != value, column)\n",
    "\n",
    "training = training.withColumn(\"age\", replace(col(\"age\"), 999)) # change age value coded as unknown (999) to null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.filter(training.age == 999).count() # yes - 999 codes have been replaced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|ucd_short| count|\n",
      "+---------+------+\n",
      "|        I|674836|\n",
      "|        C|477413|\n",
      "|        J|216611|\n",
      "|        G|159912|\n",
      "|        F|111510|\n",
      "+---------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.groupby(\"ucd_short\").count().orderBy('count', ascending=False).show(5) # top 5 causes of death with counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---+---+--------------+--------------------+---------+\n",
      "|ucd|education|sex|age|marital_status|hispanic_race_recode|ucd_short|\n",
      "+---+---------+---+---+--------------+--------------------+---------+\n",
      "|  0|    54142|  0|382|         16592|                7871|        0|\n",
      "+---+---------+---+---+--------------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.select([count(when(col(c).isNull(), c)).alias(c) for c in training.columns]).show() # rows with null values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200579"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.count() # rows in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null or nans\n",
    "training = training.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2136639"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9055989355528666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 - (2136639/2200579))*100 # dropped 2.9% of dataset because of null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StringIndexer transformers to encode categorical features as numerical for vector assembly.\n",
    "# Can't make this work with multiple columns but docs say it's possible.  spark 3.0 difference?\n",
    "\n",
    "indexer1 = StringIndexer(inputCol=\"marital_status\", outputCol=\"marital_status_index\")\n",
    "indexer2 = StringIndexer(inputCol=\"sex\", outputCol=\"sex_index\")\n",
    "indexer3 = StringIndexer(inputCol='ucd_short', outputCol='ucd_short_c')\n",
    "\n",
    "indexed1 = indexer1.fit(training).transform(training)\n",
    "indexed2 = indexer2.fit(indexed1).transform(indexed1)\n",
    "indexed = indexer3.fit(indexed2).transform(indexed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+---+---+--------------+--------------------+---------+--------------------+---------+-----------+\n",
      "| ucd|education|sex|age|marital_status|hispanic_race_recode|ucd_short|marital_status_index|sex_index|ucd_short_c|\n",
      "+----+---------+---+---+--------------+--------------------+---------+--------------------+---------+-----------+\n",
      "|K746|        6|  M| 85|             M|                   6|        K|                 0.0|      0.0|        7.0|\n",
      "|I249|        6|  M|100|             D|                   6|        I|                 2.0|      0.0|        0.0|\n",
      "|N321|        3|  F| 66|             M|                   6|        N|                 0.0|      1.0|        8.0|\n",
      "| W19|        1|  F| 94|             W|                   6|        W|                 1.0|      1.0|       10.0|\n",
      "| W18|        1|  F| 92|             S|                   4|        W|                 3.0|      1.0|       10.0|\n",
      "+----+---------+---+---+--------------+--------------------+---------+--------------------+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|ucd_short_c|ucd_short|\n",
      "+-----------+---------+\n",
      "|        0.0|        I|\n",
      "|        1.0|        C|\n",
      "|        2.0|        J|\n",
      "|        3.0|        G|\n",
      "|        4.0|        F|\n",
      "|        5.0|        X|\n",
      "|        6.0|        E|\n",
      "|        7.0|        K|\n",
      "|        8.0|        N|\n",
      "|        9.0|        A|\n",
      "|       10.0|        W|\n",
      "|       11.0|        V|\n",
      "|       12.0|        R|\n",
      "|       13.0|        D|\n",
      "|       14.0|        B|\n",
      "|       15.0|        Y|\n",
      "|       16.0|        M|\n",
      "|       17.0|        P|\n",
      "|       18.0|        Q|\n",
      "|       19.0|        L|\n",
      "|       20.0|        O|\n",
      "|       21.0|        H|\n",
      "|       22.0|        U|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save UCD mappings \n",
    "ucd_xref = indexed.select('ucd_short_c', 'ucd_short').distinct()\n",
    "ucd_xref.sort('ucd_short_c').show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder transformer to prepare categorical features for model\n",
    "encoder = OneHotEncoderEstimator(inputCols =[\"hispanic_race_recode\", \"education\", \"marital_status_index\"],\n",
    "                                 outputCols = [\"cat_hispanic_race_recode\", \"cat_education\", \"cat_marital_status\"])\n",
    "\n",
    "\n",
    "model = encoder.fit(indexed)\n",
    "encoded = model.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorAssembler to package the features for model\n",
    "assembler = VectorAssembler(inputCols=[\"cat_hispanic_race_recode\", \"cat_education\", \"cat_marital_status\", \"sex_index\", \"age\"],\n",
    "                            outputCol=\"features\")\n",
    "output = assembler.transform(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup = output.select(\"ucd_short_c\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, holdout_set = cleanup.randomSplit(weights=[0.8, 0.2], seed=212) ## split into train set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|ucd_short_c| count|\n",
      "+-----------+------+\n",
      "|       22.0|     2|\n",
      "|       21.0|    91|\n",
      "|       20.0|   698|\n",
      "|       19.0|  2992|\n",
      "|       18.0|  5881|\n",
      "|       17.0|  6413|\n",
      "|       16.0|  8471|\n",
      "|       15.0|  8516|\n",
      "|       14.0| 10063|\n",
      "|       13.0| 16737|\n",
      "|       12.0| 20135|\n",
      "|       11.0| 25557|\n",
      "|       10.0| 30051|\n",
      "|        9.0| 33139|\n",
      "|        8.0| 43393|\n",
      "|        7.0| 65607|\n",
      "|        6.0| 76747|\n",
      "|        5.0| 78917|\n",
      "|        4.0| 86335|\n",
      "|        3.0|125333|\n",
      "|        2.0|167798|\n",
      "|        1.0|372852|\n",
      "|        0.0|523784|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set.groupby(\"ucd_short_c\").count().sort('count').show(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are only 2 observations for group '22' and 91 for group '21' - filter out for now \n",
    "train_set = train_set.filter(train_set.ucd_short_c != 22)\n",
    "train_set = train_set.filter(train_set.ucd_short_c != 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1709419"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|ucd_short_c| count|\n",
      "+-----------+------+\n",
      "|       20.0|   698|\n",
      "|       19.0|  2992|\n",
      "|       18.0|  5881|\n",
      "|       17.0|  6413|\n",
      "|       16.0|  8471|\n",
      "|       15.0|  8516|\n",
      "|       14.0| 10063|\n",
      "|       13.0| 16737|\n",
      "|       12.0| 20135|\n",
      "|       11.0| 25557|\n",
      "|       10.0| 30051|\n",
      "|        9.0| 33139|\n",
      "|        8.0| 43393|\n",
      "|        7.0| 65607|\n",
      "|        6.0| 76747|\n",
      "|        5.0| 78917|\n",
      "|        4.0| 86335|\n",
      "|        3.0|125333|\n",
      "|        2.0|167798|\n",
      "|        1.0|372852|\n",
      "|        0.0|523784|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_set.groupby(\"ucd_short_c\").count().sort('count').show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.select('ucd_short_c').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now 21 different outcomes for UCD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balance training data with downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of observations that are circulatory\n",
    "class_i = train_set.filter(train_set.ucd_short_c == '0.0').count()\n",
    "class_i_pct = class_i / (train_set.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Percent Circulatory: 30.64105406573813%\n"
     ]
    }
   ],
   "source": [
    "print('Initial Percent Circulatory: ' + str(class_i_pct*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function to do downsampling\n",
    "\n",
    "def downSample(df, target, seed):\n",
    "    \n",
    "    # gather counts of each class \n",
    "    class_counts = df.groupby(target).count()\n",
    "\n",
    "    # select smallest count size and corresponding class\n",
    "    smallest_class_size = class_counts.agg({'count': 'min'})\n",
    "    smallest_class_size = smallest_class_size.collect()[0]['min(count)']\n",
    "\n",
    "    # generate ratio of each class to smallest class - for use with .sample()\n",
    "    class_counts = class_counts.withColumn('min', lit(smallest_class_size))\n",
    "    class_counts = class_counts.withColumn('ratio', class_counts['min']/ class_counts['count'])\n",
    "\n",
    "    smallest_class = class_counts.filter(class_counts['count'] == class_counts['min']).collect()[0][target]\n",
    "    \n",
    "    # set up final dataframe to hold results - with only the smallest class to start\n",
    "    adjusted_df = df.filter(df[target] == smallest_class)\n",
    "\n",
    "    # iterate over outcome classes, sampling to match count of smallest class\n",
    "    for i in range(class_counts.count()):\n",
    "\n",
    "        outcome_class = class_counts.collect()[i][target]\n",
    "        ratio = class_counts.collect()[i]['ratio']\n",
    "\n",
    "        if outcome_class != smallest_class: \n",
    "\n",
    "            subset = df.filter(df[target] == outcome_class)\n",
    "            subset_adjusted = subset.sample(False, ratio, seed = seed)\n",
    "\n",
    "            adjusted_df = adjusted_df.unionAll(subset_adjusted)\n",
    "            \n",
    "        else:\n",
    "            adjusted_df = adjusted_df\n",
    "\n",
    "    return adjusted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|ucd_short_c|count|\n",
      "+-----------+-----+\n",
      "|        0.0|  661|\n",
      "|       14.0|  679|\n",
      "|        1.0|  682|\n",
      "|       18.0|  686|\n",
      "|       16.0|  697|\n",
      "|        5.0|  697|\n",
      "|       20.0|  698|\n",
      "|        8.0|  700|\n",
      "|       15.0|  701|\n",
      "|       19.0|  704|\n",
      "|       17.0|  705|\n",
      "|        9.0|  708|\n",
      "|       12.0|  712|\n",
      "|        4.0|  713|\n",
      "|        7.0|  717|\n",
      "|        3.0|  718|\n",
      "|       10.0|  720|\n",
      "|        6.0|  722|\n",
      "|       13.0|  723|\n",
      "|        2.0|  730|\n",
      "|       11.0|  740|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adj_train = downSample(df = train_set, target = 'ucd_short_c', seed = 4)\n",
    "adj_train.groupby(\"ucd_short_c\").count().sort('count').show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusted percentage of observations that are circulatory\n",
    "class_i = adj_train.filter(adj_train.ucd_short_c == '0.0').count()\n",
    "class_i_pct = class_i / (adj_train.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Percent Circulatory: 4.462296631337339%\n"
     ]
    }
   ],
   "source": [
    "print('Adjusted Percent Circulatory: ' + str(class_i_pct*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/2.4.7/ml-classification-regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"ucd_short_c\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = dt.fit(adj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_train_output = dt_model.transform(adj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"ucd_short_c\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(dt_train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_train_output.groupby('ucd_short_c').count().show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_train_output.groupby('prediction').count().show(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Accuracy: 19.570647404307028%\n"
     ]
    }
   ],
   "source": [
    "print('DT Accuracy: ' + str(accuracy*100) + '%')\n",
    "# print('DT Test Error: ' + str((1.0 - accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_e1e941a52b26) of depth 5 with 39 nodes\n"
     ]
    }
   ],
   "source": [
    "print(dt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "\n",
    "# # save model\n",
    "# dt_model.save('home/ds5559/final_project/models/dt_model')\n",
    "# modeldf = spark.read.parquet('home/ds5559/final_project/models/dt_model/'+\"data/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualize decision tree\n",
    "# noderows = modeldf.select(\"id\",\"prediction\",\"leftChild\",\"rightChild\",\"split\").collect()\n",
    "# df = pd.Dataframe([[rw['id'],rw['gain],rw['impurity'],rw['gini']] for rw in noderows if rw['leftChild'] < 0 and rw['rightChild'] < 0])\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predictions = dt_model.transform(holdout_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_predictions.groupby(\"prediction\").count().sort('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred_accuracy = evaluator.evaluate(dt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Hold-out Set Prediction Accuracy: 12.832951323611011%\n"
     ]
    }
   ],
   "source": [
    "print('DT Hold-out Set Prediction Accuracy: ' + str(dt_pred_accuracy*100) + '%')\n",
    "# print('DT Hold-out Set Test Error: ' + str((1.0 - dt_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol='ucd_short_c', featuresCol=\"features\", numTrees=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = rf.fit(adj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_output = rf_model.transform(adj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"ucd_short_c\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "rf_accuracy = evaluator.evaluate(rf_train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy: 20.31998919867684%\n"
     ]
    }
   ],
   "source": [
    "print('RF Accuracy: ' + str(rf_accuracy*100) + '%')\n",
    "# print('RF Test Error: ' + str((1.0 - rf_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassificationModel (uid=RandomForestClassifier_69cf05bd1001) with 100 trees\n"
     ]
    }
   ],
   "source": [
    "print(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions = rf_model.transform(holdout_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_predictions.groupby(\"prediction\").count().sort('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_accuracy = evaluator.evaluate(rf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Hold-out Set Prediction Accuracy: 13.406551213105237%\n"
     ]
    }
   ],
   "source": [
    "print('RF Hold-out Set Prediction Accuracy: ' + str(rf_pred_accuracy*100) + '%')\n",
    "# print('RF Hold-out Set Test Error: ' + str((1.0 - rf_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(labelCol='ucd_short_c', featuresCol=\"features\", smoothing=1.0, modelType=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = nb.fit(adj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_output = nb_model.transform(adj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"ucd_short_c\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "nb_accuracy = evaluator.evaluate(nb_train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Accuracy: 16.809559170998448%\n"
     ]
    }
   ],
   "source": [
    "print('NB Accuracy: ' + str(nb_accuracy*100) + '%')\n",
    "# print('RF Test Error: ' + str((1.0 - rf_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes_d1461db29d2d\n"
     ]
    }
   ],
   "source": [
    "print(nb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = nb_model.transform(holdout_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_predictions.groupby(\"prediction\").count().sort('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pred_accuracy = evaluator.evaluate(nb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Validation Hold-out Set Prediction Accuracy: 11.735853739051851%\n"
     ]
    }
   ],
   "source": [
    "print('NB Validation Hold-out Set Prediction Accuracy: ' + str(nb_pred_accuracy*100) + '%')\n",
    "# print('RF Hold-out Set Test Error: ' + str((1.0 - rf_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "mlr = LogisticRegression(labelCol='ucd_short_c', featuresCol=\"features\", family = \"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_model = mlr.fit(adj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(str(mlr_model.coefficientMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_train_output = mlr_model.transform(adj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"ucd_short_c\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "mlr_accuracy = evaluator.evaluate(mlr_train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR Accuracy: 19.860932964288125%\n"
     ]
    }
   ],
   "source": [
    "print('MLR Accuracy: ' + str(mlr_accuracy*100) + '%')\n",
    "# print('MLR Test Error: ' + str((1.0 - mlr_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionModel: uid = LogisticRegression_c7cbb7f25e66, numClasses = 23, numFeatures = 30\n"
     ]
    }
   ],
   "source": [
    "print(mlr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_predictions = mlr_model.transform(holdout_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlr_predictions.groupby(\"prediction\").count().sort('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_pred_accuracy = evaluator.evaluate(mlr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR Hold-out Set Prediction Accuracy: 11.235534161970563%\n"
     ]
    }
   ],
   "source": [
    "print('MLR Hold-out Set Prediction Accuracy: ' + str(mlr_pred_accuracy*100) + '%')\n",
    "# print('MLR Hold-out Set Test Error: ' + str((1.0 - mlr_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Hold-Out Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550650"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in test data\n",
    "test_data = spark.read.option(\"header\",True).option(\"inferSchema\",True).csv(\"test_data\")\n",
    "test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset with potential features\n",
    "testing = test_data.select(\"ucd\", \"education\", \"sex\", \"age\", \"marital_status\", \"hispanic_race_recode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip UCD codes to include first letter only\n",
    "testing = testing.withColumn(\"ucd_short\", regexp_replace('ucd', '\\\\d+', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+---+---+--------------+--------------------+---------+\n",
      "| ucd|education|sex|age|marital_status|hispanic_race_recode|ucd_short|\n",
      "+----+---------+---+---+--------------+--------------------+---------+\n",
      "| C61|        1|  M| 82|             M|                   7|        C|\n",
      "|E142|        1|  F| 74|             M|                   1|        E|\n",
      "|I429|        2|  M| 70|             S|                   8|        I|\n",
      "|C349|        3|  M| 89|             W|                   6|        C|\n",
      "|I119|        3|  M| 67|             S|                   7|        I|\n",
      "+----+---------+---+---+--------------+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace age coding values: \n",
    "testing = testing.withColumn(\"age\", replace(col(\"age\"), 999)) # change age value coded as unknown (999) to null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null or nans\n",
    "testing = testing.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534741"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join with ucd_short_c cross reference - want to ensure that string indexing matches between train and test data!\n",
    "testing = testing.join(ucd_xref, on = 'ucd_short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---------+---+---+--------------+--------------------+-----------+\n",
      "|ucd_short| ucd|education|sex|age|marital_status|hispanic_race_recode|ucd_short_c|\n",
      "+---------+----+---------+---+---+--------------+--------------------+-----------+\n",
      "|        K|K922|        3|  F| 94|             W|                   6|        7.0|\n",
      "|        K|K746|        2|  M| 72|             M|                   6|        7.0|\n",
      "|        K|K650|        3|  M| 86|             W|                   6|        7.0|\n",
      "|        K|K922|        3|  F| 81|             W|                   6|        7.0|\n",
      "|        K|K746|        3|  F| 72|             M|                   6|        7.0|\n",
      "+---------+----+---------+---+---+--------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StringIndexer transformers to encode categorical features as numerical for vector assembly.\n",
    "# leaving off the ucd indexer here - already joined with ucd_xref\n",
    "indexed1 = indexer1.fit(testing).transform(testing)\n",
    "indexed = indexer2.fit(indexed1).transform(indexed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+---------+---+---+--------------+--------------------+-----------+--------------------+---------+\n",
      "|ucd_short| ucd|education|sex|age|marital_status|hispanic_race_recode|ucd_short_c|marital_status_index|sex_index|\n",
      "+---------+----+---------+---+---+--------------+--------------------+-----------+--------------------+---------+\n",
      "|        K|K922|        3|  F| 94|             W|                   6|        7.0|                 1.0|      1.0|\n",
      "|        K|K746|        2|  M| 72|             M|                   6|        7.0|                 0.0|      0.0|\n",
      "+---------+----+---------+---+---+--------------+--------------------+-----------+--------------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder transformer to prepare categorical features for model\n",
    "model = encoder.fit(indexed)\n",
    "encoded = model.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorAssembler to package the features for model\n",
    "assembler = VectorAssembler(inputCols=[\"cat_hispanic_race_recode\", \"cat_education\", \"cat_marital_status\", \"sex_index\", \"age\"],\n",
    "                            outputCol=\"features\")\n",
    "output = assembler.transform(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup = output.select(\"ucd_short_c\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|ucd_short_c|count|\n",
      "+-----------+-----+\n",
      "|       21.0|   21|\n",
      "|       20.0|  209|\n",
      "|       19.0|  951|\n",
      "|       18.0| 1745|\n",
      "|       17.0| 1990|\n",
      "+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanup.groupby(\"ucd_short_c\").count().sort('count').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out groups '20' and '21' (consistent with training data pre-processing)\n",
    "cleanup = cleanup.filter(cleanup.ucd_short_c != 22)\n",
    "cleanup = cleanup.filter(cleanup.ucd_short_c != 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling - Holdout Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predictions_f = dt_model.transform(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pred_accuracy_f = evaluator.evaluate(dt_predictions_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Final Hold-out Set Prediction Accuracy: 12.8038973668462%\n"
     ]
    }
   ],
   "source": [
    "print('DT Final Hold-out Set Prediction Accuracy: ' + str(dt_pred_accuracy_f*100) + '%')\n",
    "# print('DT Hold-out Set Test Error: ' + str((1.0 - dt_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions_f = rf_model.transform(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_accuracy_f = evaluator.evaluate(rf_predictions_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Final Hold-out Set Prediction Accuracy: 13.530632854578098%\n"
     ]
    }
   ],
   "source": [
    "print('RF Final Hold-out Set Prediction Accuracy: ' + str(rf_pred_accuracy_f*100) + '%')\n",
    "# print('DT Hold-out Set Test Error: ' + str((1.0 - dt_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions_f = nb_model.transform(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pred_accuracy_f = evaluator.evaluate(nb_predictions_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Validation Hold-out Set Prediction Accuracy: 11.839654398563734%\n"
     ]
    }
   ],
   "source": [
    "print('NB Validation Hold-out Set Prediction Accuracy: ' + str(nb_pred_accuracy_f*100) + '%')\n",
    "# print('MLR Hold-out Set Test Error: ' + str((1.0 - mlr_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_predictions_f = mlr_model.transform(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_pred_accuracy_f = evaluator.evaluate(mlr_predictions_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR Validation Hold-out Set Prediction Accuracy: 11.355662776780372%\n"
     ]
    }
   ],
   "source": [
    "print('MLR Validation Hold-out Set Prediction Accuracy: ' + str(mlr_pred_accuracy_f*100) + '%')\n",
    "# print('MLR Hold-out Set Test Error: ' + str((1.0 - mlr_pred_accuracy)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_summary = mlr_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = mlr_summary.accuracy\n",
    "falsePositiveRate = mlr_summary.weightedFalsePositiveRate\n",
    "truePositiveRate = mlr_summary.weightedTruePositiveRate\n",
    "fMeasure = mlr_summary.weightedFMeasure()\n",
    "precision = mlr_summary.weightedPrecision\n",
    "recall = mlr_summary.weightedRecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.19860932964288125\n",
      "FPR: 0.040155544409270445\n",
      "TPR: 0.19860932964288122\n",
      "F-measure: 0.15711806130007133\n",
      "Precision: 0.15779374904089258\n",
      "Recall: 0.19860932964288122\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/thd6tp/ds5559/final_project/Classification_Models.ipynb to pdf\n",
      "[NbConvertApp] Writing 85847 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 74703 bytes to /sfs/qumulo/qhome/thd6tp/ds5559/final_project/Classification_Models.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/thd6tp/ds5559/final_project/Classification_Models_DS.ipynb to pdf\n",
      "[NbConvertApp] Writing 98157 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 83894 bytes to /sfs/qumulo/qhome/thd6tp/ds5559/final_project/Classification_Models_DS.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/thd6tp/ds5559/final_project/LogRegModel_Demog.ipynb to pdf\n",
      "[NbConvertApp] Writing 130503 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 114195 bytes to /sfs/qumulo/qhome/thd6tp/ds5559/final_project/LogRegModel_Demog.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/thd6tp/ds5559/final_project/Pipelines.ipynb to pdf\n",
      "[NbConvertApp] Writing 21300 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 13833 bytes to /sfs/qumulo/qhome/thd6tp/ds5559/final_project/Pipelines.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/thd6tp/ds5559/final_project/TreeModels_DownSample_TDP.ipynb to pdf\n",
      "[NbConvertApp] Writing 108228 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 94158 bytes to /sfs/qumulo/qhome/thd6tp/ds5559/final_project/TreeModels_DownSample_TDP.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/thd6tp/ds5559/final_project/TreeModels_TDP.ipynb to pdf\n",
      "[NbConvertApp] Writing 57450 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 59828 bytes to /sfs/qumulo/qhome/thd6tp/ds5559/final_project/TreeModels_TDP.pdf\n",
      "[NbConvertApp] Converting notebook /sfs/qumulo/qhome/thd6tp/ds5559/final_project/secondary_cause_PC.ipynb to pdf\n",
      "[NbConvertApp] Writing 60958 bytes to ./notebook.tex\n",
      "[NbConvertApp] Building PDF\n",
      "[NbConvertApp] Running xelatex 3 times: ['xelatex', './notebook.tex', '-quiet']\n",
      "[NbConvertApp] Running bibtex 1 time: ['bibtex', './notebook']\n",
      "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
      "[NbConvertApp] PDF successfully created\n",
      "[NbConvertApp] Writing 56252 bytes to /sfs/qumulo/qhome/thd6tp/ds5559/final_project/secondary_cause_PC.pdf\n"
     ]
    }
   ],
   "source": [
    "# Save notebook as PDF document\n",
    "!jupyter nbconvert --to pdf `pwd`/*.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
